{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06229cffe52a28d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T08:58:15.916292408Z",
     "start_time": "2023-09-11T08:58:14.547580672Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import lightgbm as lightgbm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "def read_data(path):\n",
    "    if path.endswith(\".svm\"):\n",
    "        data = load_svmlight_file(path, query_id=True)\n",
    "        return data[0], data[1], data[2]\n",
    "    elif path.endswith(\".jsonl\"):\n",
    "        data = pd.read_json(path_or_buf=path, lines=True)\n",
    "        return data\n",
    "    elif path.endswith(\".txt\"):\n",
    "        data = pd.read_csv(path, sep=\" \")\n",
    "        return data\n",
    "    else:\n",
    "        print(\"Invalid path\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b3fa314830ccf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T08:58:25.445948931Z",
     "start_time": "2023-09-11T08:58:25.072937054Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/data/Soheil-data/Python Projects/KNN-LETOR/train_svm_features_avg.pkl', 'rb') as f:\n",
    "    preprocessed_train_cum_features = pickle.load(f) #main dict train with qids and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46687be3ff90a798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T08:58:34.036498085Z",
     "start_time": "2023-09-11T08:58:33.884522513Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/data/Soheil-data/Python Projects/KNN-LETOR/test_svm_features_avg.pkl', 'rb') as f:\n",
    "    preprocessed_test_cum_features = pickle.load(f) #main dict with test qids and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e882cc594d0082",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T09:00:35.262256708Z",
     "start_time": "2023-09-11T08:58:38.874160692Z"
    }
   },
   "outputs": [],
   "source": [
    "train_svm_directory = \"/data/Sepehr-data/istella22/train.svm\"\n",
    "train_svm_features, train_svm_relevance, train_svm_q_id = read_data(train_svm_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e9826",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_train_svm_features =  train_svm_features.toarray()\n",
    "df_train_svm_features = pd.DataFrame({\"features\": [row for row in arr_train_svm_features], \"q_id\": train_svm_q_id, \"relevance\": train_svm_relevance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_svm_features['q_id'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c452daa59f3064c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T09:02:39.039024364Z",
     "start_time": "2023-09-11T09:00:35.263272580Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/data/Soheil-data/Python Projects/KNN-LETOR/test_svm_features_rel.pkl', 'rb') as f:\n",
    "    test_data_all = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a13e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_cum_features= pd.DataFrame(preprocessed_train_cum_features)\n",
    "preprocessed_test_cum_features= pd.DataFrame(preprocessed_test_cum_features)\n",
    "train_data_all= df_train_svm_features#pd.DataFrame(train_data_all)\n",
    "test_data_all= pd.DataFrame(test_data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_svm_features = []\n",
    "train_svm_relevance = []\n",
    "train_svm_q_id =[]\n",
    "qid_avg_train = preprocessed_train_cum_features[\"q_id\"].tolist()\n",
    "features_avg_train = preprocessed_train_cum_features[\"features\"].tolist()\n",
    "qid_avg_train = np.vstack(qid_avg_train)\n",
    "features_avg_train = np.vstack(features_avg_train)\n",
    "preprocessed_train_cum_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ddba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_avg_test = preprocessed_test_cum_features[\"q_id\"].tolist()\n",
    "features_avg_test = preprocessed_test_cum_features[\"features\"].tolist()\n",
    "qid_avg_test = np.vstack(qid_avg_test)\n",
    "features_avg_test = np.vstack(features_avg_test)\n",
    "preprocessed_test_cum_features = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb4ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_all_train= train_data_all[\"q_id\"].tolist()\n",
    "\n",
    "relevance_all_train = train_data_all[\"relevance\"].tolist()\n",
    "features_all_train = train_data_all[\"features\"].tolist()\n",
    "qid_all_train = np.vstack(qid_all_train)\n",
    "relevance_all_train = np.vstack(relevance_all_train)\n",
    "features_all_train = np.vstack(features_all_train)\n",
    "train_data_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ef9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_all = []\n",
    "\n",
    "qid_all_test = test_data_all[\"q_id\"].tolist()\n",
    "relevance_all_test = test_data_all[\"relevance\"].tolist()\n",
    "features_all_test = test_data_all[\"features\"].tolist()\n",
    "qid_all_test = np.vstack(qid_all_test)\n",
    "relevance_all_test = np.vstack(relevance_all_test)\n",
    "features_all_test = np.vstack(features_all_test)\n",
    "test_data_all= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8321d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique elements and their counts\n",
    "unique_elements, counts = np.unique(qid_all_test, return_counts=True)\n",
    "\n",
    "# Print the counts for each unique element\n",
    "for element, count in zip(unique_elements, counts):\n",
    "    if(count == 1):\n",
    "        print(f\"Element {element} appears {count} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58bc081ddfb506",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#find the nearest neighbour\n",
    "#key2: features\n",
    "#key1: qids\n",
    "def get_nearest_neighbour(test_q, features_avg_train,k):\n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "    features_avg_train = np.array(features_avg_train)\n",
    "    \n",
    "    knn.fit(features_avg_train)\n",
    "    test_q = test_q.reshape((1, -1))\n",
    "    dist_loc = knn.kneighbors(test_q)\n",
    "    dist = dist_loc[0]\n",
    "    loc = dist_loc[1]\n",
    "    return dist, loc\n",
    "#these have relevance score, qids, and features\n",
    "#key_0 = relevance score, key_qids, key2_features list\n",
    "\"\"\"\n",
    "test_unique_qids = []    # a list for getting the qids of tests\n",
    "for d in qid_avg_test:\n",
    "    if d not in test_unique_qids:\n",
    "        test_unique_qids.append(d)\n",
    "\"\"\"\n",
    "k_n= 300\n",
    "#qids_test = []\n",
    "ncdg_cum = []\n",
    "for i in range(0,len(qid_avg_test)):\n",
    "   \n",
    "    #get features corresponding to the qids of the test\n",
    "    #qids_test.append(qid)\n",
    "    #test_q = #[d['features'] for d in preprocessed_train_cum_features if d.get('q_id') == key1_value]\n",
    "    #get the nearest neighbour of the test_q\n",
    "    test_feature = features_avg_test[i]\n",
    "    \n",
    "    features_avg_test = features_avg_test.reshape((features_avg_test.shape[0],-1))\n",
    "    \n",
    "    features_avg_train = features_avg_train.reshape((features_avg_train.shape[0], 220))\n",
    "    \n",
    "    dist , loc = get_nearest_neighbour(test_feature, features_avg_train,k_n)\n",
    "    print(\"KNN done...\")\n",
    "    #get the values of the second key(features) of the trainset\n",
    "    selected_train_set = features_avg_train[loc]\n",
    "    #get the nearest query ids and add them to this list\n",
    "    matching_train_qids = qid_avg_train[loc]\n",
    "    matching_train_qids = matching_train_qids.reshape(-1,1)\n",
    "    new_train_features = []\n",
    "    new_train_qids = []\n",
    "    new_train_relevances = []\n",
    "   \n",
    "    #for qid in matching_train_qids:  \n",
    "    #indices = np.where(np.isin(qid_all_train, matching_train_qids))[0]\n",
    "    new_train_qids.append(qid_all_train[np.where(np.isin(qid_all_train, matching_train_qids))[0]])\n",
    "    new_train_features.append(features_all_train[np.where(np.isin(qid_all_train, matching_train_qids))[0]])\n",
    "    new_train_relevances.append(relevance_all_train[np.where(np.isin(qid_all_train, matching_train_qids))[0]])\n",
    "    \n",
    "    \"\"\"\n",
    "    new_train_qids.append(qid_all_train[np.where(qid_all_train == matching_train_qids)[0]])\n",
    "    new_train_features.append(features_all_train[np.where(qid_all_train == matching_train_qids)[0]])\n",
    "    new_train_relevances.append(relevance_all_train[np.where(qid_all_train == matching_train_qids)[0]])\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    for j in range(0, len(train_data_ids)):\n",
    "        new_train_qids.append(qid_all_train[train_data_ids[j]])\n",
    "        new_train_features.append(features_all_train[train_data_ids[j]])\n",
    "        new_train_relevances.append(relevance_all_train[train_data_ids[j]])\n",
    "    \"\"\"\n",
    "    \n",
    "    new_train_relevances = np.array(new_train_relevances)\n",
    "    new_train_features = np.array(new_train_features[0])\n",
    "    new_train_qids = np.array(new_train_qids)\n",
    "\n",
    "    # Reshape \"relevance\" and \"qid\" arrays\n",
    "    new_train_relevances = new_train_relevances.reshape(-1)\n",
    "    new_train_qids = new_train_qids.reshape(-1)\n",
    "    #new_train_features = new_train_features.tolist()\n",
    "    # Concatenate arrays and list\n",
    "    #train_data = np.column_stack((new_train_relevances, new_train_qids, new_train_features))\n",
    "    data_train_tmp = {\n",
    "    'relevance': new_train_relevances,\n",
    "    'qid': new_train_qids,\n",
    "    'features': new_train_features.tolist()  # Convert features to a list of lists\n",
    "    }\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    train_group = pd.DataFrame(data_train_tmp)\n",
    "    \n",
    "    test_data_ids = np.where(qid_all_test == qid_avg_test[i])[0]\n",
    "    new_test_qids = []\n",
    "    new_test_features = []\n",
    "    new_test_relevances = []\n",
    "    \n",
    "    for j in range(0, len(test_data_ids)):\n",
    "            new_test_qids.append(qid_all_test[test_data_ids[j]])\n",
    "            new_test_features.append(features_all_test[test_data_ids[j]])\n",
    "            new_test_relevances.append(relevance_all_test[test_data_ids[j]])\n",
    "    \n",
    "    new_test_qids = np.array(new_test_qids)\n",
    "    new_test_features = np.array(new_test_features)\n",
    "    new_test_relevances = np.array(new_test_relevances)\n",
    "    \n",
    "    new_test_relevances = new_test_relevances.reshape(-1)\n",
    "    new_test_qids = new_test_qids.reshape(-1)\n",
    "    \n",
    "    data_test_tmp = {\n",
    "    'relevance': new_test_relevances,\n",
    "    'qid': new_test_qids,\n",
    "    'features': new_test_features.tolist()  # Convert features to a list of lists\n",
    "    }\n",
    "    test_group = pd.DataFrame(data_test_tmp)\n",
    "    \n",
    "    qids_train = train_group.groupby(\"qid\")[\"qid\"].count().to_numpy()\n",
    "    qids_test = test_group.groupby(\"qid\")[\"qid\"].count().to_numpy()\n",
    "    \n",
    "    new_train_relevances = new_train_relevances.astype(int)\n",
    "    new_test_relevances = new_test_relevances.astype(int)\n",
    "    a = time.time()\n",
    "    ranker = lightgbm.LGBMRanker(\n",
    "                        objective=\"lambdarank\",\n",
    "                        boosting_type = \"gbdt\",\n",
    "                        #n_estimators = 1,\n",
    "                        importance_type = \"gain\",\n",
    "                        force_col_wise=True,\n",
    "                        metric= \"ndcg\",\n",
    "                        #num_leaves = 250,\n",
    "                        #learning_rate = 0.05,\n",
    "                        max_depth = -1,\n",
    "                        #min_data_in_bin=10, \n",
    "                        #max_bin=250,\n",
    "                        #device ='gpu',\n",
    "                        label_gain =[i for i in range(max(new_train_relevances.max(), new_test_relevances.max()) + 1)])\n",
    "    \n",
    "    # Training the model\n",
    "    ranker.fit(\n",
    "          X=new_train_features,\n",
    "          y=new_train_relevances,\n",
    "          group=qids_train)\n",
    "          #eval_set=[(new_train_features, new_train_relevances),(new_test_features, new_test_relevances)],\n",
    "          #eval_group=[qids_train, qids_test],\n",
    "          #eval_at=[10])\n",
    "    \n",
    "    test_pred = ranker.predict(new_test_features)\n",
    "    np.save('/data/Sepehr-data/results_online_'+str(k_n)+'/online_test_pred'+str(i)+'.npy', test_pred)\n",
    "    np.save('/data/Sepehr-data/results_online_'+str(k_n)+'/online_test_relv'+str(i)+'.npy', new_test_relevances)\n",
    "    from sklearn.metrics import ndcg_score\n",
    "    \n",
    "    new_test_relevances = new_test_relevances.reshape((1, -1))\n",
    "    test_pred = test_pred.reshape((1, -1))\n",
    "    #print(test_pred)\n",
    "    if(len(test_pred[0]) != 1):\n",
    "        ncdg_res = ndcg_score(new_test_relevances, test_pred, k=10)\n",
    "        ncdg_cum.append(ncdg_res)\n",
    "    else:\n",
    "        print(\"No NCDG...\")\n",
    "    print(\"NCDG@10: \", np.mean(ncdg_cum))\n",
    "    print(\"Test item No: \"+ str(i)+ \" of \"+ str(len(qid_avg_test)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df894337",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker.evals_result_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81cbb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(qid_avg_test)):\n",
    "    test_data_ids = np.where(qid_all_test == qid_avg_test[i])[0]\n",
    "    new_test_qids = []\n",
    "    new_test_features = []\n",
    "    new_test_relevances = []\n",
    "    for j in range(0, len(test_data_ids)):\n",
    "            new_test_qids.append(qid_all_test[test_data_ids[j]])\n",
    "            new_test_features.append(features_all_test[test_data_ids[j]])\n",
    "            new_test_relevances.append(relevance_all_test[test_data_ids[j]])\n",
    "    \n",
    "    new_test_qids = np.array(new_test_qids)\n",
    "    new_test_features = np.array(new_test_features)\n",
    "    new_test_relevances = np.array(new_test_relevances)\n",
    "    \n",
    "    new_test_relevances = new_test_relevances.reshape(-1)\n",
    "    new_test_qids = new_test_qids.reshape(-1)\n",
    "    \n",
    "    \n",
    "    from sklearn.metrics import ndcg_score\n",
    "    \n",
    "    new_test_relevances = new_test_relevances.reshape((1, -1))\n",
    "    test_pred = np.load('/data/Sepehr-data/results_online_'+k_n'/online_test_pred'+str(i)+'.npy')\n",
    "    test_pred = test_pred.reshape((1, -1))\n",
    "    \n",
    "    #print(test_pred)\n",
    "    if(len(test_pred[0]) != 1):\n",
    "        ncdg_res = ndcg_score(new_test_relevances, test_pred, k=1)\n",
    "        ncdg_cum.append(ncdg_res)\n",
    "    else:\n",
    "        print(\"No NCDG...\")\n",
    "    print(\"NCDG@10: \", np.mean(ncdg_cum))\n",
    "    print(\"Test item No: \"+ str(i)+ \" of \"+ str(len(qid_avg_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b43cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
